{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "055cace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import Language\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import LanguageParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a25b2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = \"C:\\\\Users\\\\rutvi\\\\Downloads\\\\ff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7feb79f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = GenericLoader.from_filesystem(\n",
    "    repo_path ,\n",
    "    parser=LanguageParser(language=Language.PYTHON, parser_threshold=500),\n",
    ")\n",
    "documents = loader.load()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c3612ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=2000, chunk_overlap=200\n",
    ")\n",
    "texts = python_splitter.split_documents(documents)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3843cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain import OpenAI\n",
    "import openai\n",
    "# Define prompt\n",
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "\"{text}\"\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0443126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72da4de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rutvi\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first code snippet is a method that paints a logo on a graphics object. It checks if the logo is null, and if not, it calculates the position and size of the logo and draws it on the graphics object.\n",
      "\n",
      "The second code snippet is a method that centers a component on the screen. It uses the screen size and the component's dimensions to calculate the position and sets the location of the component accordingly.\n"
     ]
    }
   ],
   "source": [
    "#Stuffing method\n",
    "\n",
    "# Define LLM chain\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\"\")\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Define StuffDocumentsChain\n",
    "stuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"text\")\n",
    "\n",
    "docs = loader.load()\n",
    "# print(docs)\n",
    "answers = stuff_chain.run(docs)\n",
    "\n",
    "\n",
    "# # Print or use stored_answers as needed\n",
    "answers.split(\"\\n\\n\")\n",
    "type(answers)\n",
    "print(answers)\n",
    "# print(stuff_chain.run(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7794fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 2 Map-Reduce\n",
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0\")\n",
    "\n",
    "# Map\n",
    "map_template = \"\"\"The following is a set of documents\n",
    "{docs}\n",
    "Based on this list of docs, please identify the main themes \n",
    "Helpful Answer:\"\"\"\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6566274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "obj = hub.pull(\"rlm/map-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9d2f7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['docs'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['docs'], template='The following is a set of documents:\\n{docs}\\nBased on this list of docs, please identify the main themes \\nHelpful Answer:'))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13a59ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce\n",
    "reduce_template = \"\"\"The following is set of summaries:\n",
    "{docs}\n",
    "Take these and distill it into a final, consolidated summary of the main themes. \n",
    "Helpful Answer:\"\"\"\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23354e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note we can also get this from the prompt hub, as noted above\n",
    "reduce_prompt = hub.pull(\"rlm/map-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39aba05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0bdcd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb75052d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['docs'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['docs'], template='The following is a set of documents:\\n{docs}\\nBased on this list of docs, please identify the main themes \\nHelpful Answer:'))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChatPromptTemplate(input_variables=['docs'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['docs'], template='The following is a set of documents:\\n{docs}\\nBased on this list of docs, please identify the main themes \\nHelpful Answer:'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c63cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chain\n",
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "# Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"docs\"\n",
    ")\n",
    "\n",
    "# Combines and iteratively reduces the mapped documents\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # This is final chain that is called.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # If documents exceed context for `StuffDocumentsChain`\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # The maximum number of tokens to group documents into.\n",
    "    token_max=4000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2cc62449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "118dbc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining documents by mapping a chain over them, then combining results\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    # Map chain\n",
    "    llm_chain=map_chain,\n",
    "    # Reduce chain\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    # The variable name in the llm_chain to put the documents in\n",
    "    document_variable_name=\"docs\",\n",
    "    # Return the results of the map steps in the output\n",
    "    return_intermediate_steps=False,\n",
    ")\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=0\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d4f1c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main themes identified in these documents are painting or displaying a logo/icon using graphics in a software application and centering a component on the screen.\n"
     ]
    }
   ],
   "source": [
    "print(map_reduce_chain.run(split_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c2fbaf81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The code snippet defines a method to paint a logo on a graphics object. If the logo is null, the method returns. The logo is then drawn at a specific position on the graphics object. The comment indicates that the method paints the icon. Additionally, a method is provided to center a component on the screen.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MEthod 3\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
    "chain.run(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7bbd0579",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "{text}\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "refine_template = (\n",
    "    \"Your job is to produce a final summary\\n\"\n",
    "    \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "    \"We have the opportunity to refine the existing summary\"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Given the new context, refine the original summary in gujarati\"\n",
    "    \"If the context isn't useful, return the original summary.\"\n",
    ")\n",
    "refine_prompt = PromptTemplate.from_template(refine_template)\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    question_prompt=prompt,\n",
    "    refine_prompt=refine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    "    input_key=\"input_documents\",\n",
    "    output_key=\"output_text\",\n",
    ")\n",
    "result = chain({\"input_documents\": split_docs}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "19fcc38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "àª®à«‡àª¥àª¡ paintLogo àª¨à«‡ àªµàª§à« àª¸àª‚àª¦àª°à«àª­ àª¸àª¾àª¥à«‡ àª¸à«àª§àª¾àª°à«‹ àª•àª°àªµàª¾àª¨à«€ àª†àªµàª¶à«àª¯àª•àª¤àª¾ àª¨àª¥à«€, àª¤à«‡àª¨à«€ àª®à«‚àª³ àª¸àª¾àª°àª¾àª‚àª¶ àªªàª°àª‚àª¤à« àªªà«‚àª°à«àª£ àª›à«‡: àªœà«‹ àª²à«‹àª—à«‹ àª†àª‡àª•à«‹àª¨ àª¨àª² àª¹à«‹àª¯, àª¤à«‹ àª¤à«‡ àª¨àª¿àª°à«àª¦àª¿àª·à«àªŸ àªªàª¹à«‹àª³àª¾ àª…àª¨à«‡ àªŠàª‚àªšàª¾àªˆàª¨à«‹ àª‰àªªàª¯à«‹àª— àª•àª°à«€àª¨à«‡ àª¸à«àª•à«àª°à«€àª¨ àªªàª° àª²à«‹àª—à«‹ àª†àª‡àª•à«‹àª¨ àªªà«‡àª‡àª¨à«àªŸ àª•àª°à«‡ àª›à«‡.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"output_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "90c0e0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paintLogo method paints the logo icon on the screen if it is not null, using the specified width and height.\n",
      "\n",
      "àª®à«‡àª¥àª¡ paintLogo àª¨à«‡ àªµàª§à« àª¸àª‚àª¦àª°à«àª­ àª¸àª¾àª¥à«‡ àª¸à«àª§àª¾àª°à«‹ àª•àª°àªµàª¾àª¨à«€ àª†àªµàª¶à«àª¯àª•àª¤àª¾ àª¨àª¥à«€, àª¤à«‡àª¨à«€ àª®à«‚àª³ àª¸àª¾àª°àª¾àª‚àª¶ àªªàª°àª‚àª¤à« àªªà«‚àª°à«àª£ àª›à«‡: àªœà«‹ àª²à«‹àª—à«‹ àª†àª‡àª•à«‹àª¨ àª¨àª² àª¹à«‹àª¯, àª¤à«‹ àª¤à«‡ àª¨àª¿àª°à«àª¦àª¿àª·à«àªŸ àªªàª¹à«‹àª³àª¾ àª…àª¨à«‡ àªŠàª‚àªšàª¾àªˆàª¨à«‹ àª‰àªªàª¯à«‹àª— àª•àª°à«€àª¨à«‡ àª¸à«àª•à«àª°à«€àª¨ àªªàª° àª²à«‹àª—à«‹ àª†àª‡àª•à«‹àª¨ àªªà«‡àª‡àª¨à«àªŸ àª•àª°à«‡ àª›à«‡.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join(result[\"intermediate_steps\"][:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d7f37763",
   "metadata": {},
   "outputs": [],
   "source": [
    "###end####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87a12d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title(\"Magical Code Summarizer ğŸ§™â€â™‚ï¸âœ¨\")\n",
    "prompt = st.chat_input(\"Code Summarizer\")\n",
    "# Initialize chat history if necessary\n",
    "if \"chat_history\" not in st.session_state:\n",
    "    st.session_state.chat_history = []\n",
    "\n",
    "\n",
    "def display_chat_history():\n",
    "    for entry in st.session_state.chat_history:\n",
    "        if entry[\"role\"] == \"user\":\n",
    "            st.markdown(f\"**You ğŸ§™â€â™‚ï¸ :** {entry['text']}\")\n",
    "        else:\n",
    "            st.markdown(f\"**Code Summarizer ğŸ“:** {entry['text']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c20e2026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The code snippets show methods in Java for painting a logo and centering a component on the screen. The paintLogo method paints a logo on a graphics object, while the center method centers a component on the screen using the default screen size and component dimensions.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\"\")\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f6934f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The code snippets show methods in Java for painting a logo and centering a component on the screen. The paintLogo method paints a logo on a graphics object, while the center method centers a component on the screen using the screen and component dimensions.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\"\")\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "chain.run(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
